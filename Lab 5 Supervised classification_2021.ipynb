{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: Supervised classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ATENTION:*** before running this lab, upgrade geemap, please go to File, New, Terminal, and pass the following command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install -U geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:**\n",
    "The purpose of this lab is introduce you to concepts of supervised classification: prediction of nominal or numeric values of a geographic variable from other geographic variables.  You will explore processes of training data collection, classifier selection, classifier training, image classification and accuracy assessment.  At the completion of the lab, you will be able to perform supervised classification in Earth Engine.\n",
    "\n",
    "**Prerequisites:** Lab 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to classification and regression\n",
    "For present purposes, define prediction as guessing the value of some geographic variable of interest *g*, using a function *G* that takes as input a pixel vector **p**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "G_{T}(p_i) = g_i \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *i* in this equation refers to a particular instance from a set of pixels.  Think of *G* as a guessing function and *gi* as the guess for pixel *i*.   The **T** in the subscript of *G* refers to a *training set* (a set of known values for p and the correct g), used to infer the structure of G.  You have to choose a suitable *G* to train with **T**.  When *g* is nominal (e.g. {'water', 'vegetation', 'bare'}), call this setup classification.  When g is numeric, call this setup regression.  This is an incredibly simplistic description of a problem addressed in a broad range of fields including mathematics, statistics, data mining, machine learning, etc.  Interested readers may see [Witten et al. (2011)](http://www.cs.waikato.ac.nz/ml/weka/book.html), [Hastie et al. (2009)](http://statweb.stanford.edu/~tibs/ElemStatLearn/) or [Goodfellow et al (2016)](http://www.deeplearningbook.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "Classification in Earth Engine has a similar workflow to regression: build the training, train the classifier, classify an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification, g is nominal.  The first step is to create training data manually.  (Alternatively, upload a shapefile  training data (of points or polygons), for example data collected on the ground with a GPS).  Using Google Earth we can also digitize training polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cd89d2e09b4fbcb732bf888f1489ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "import geemap\n",
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import a Landsat 8 image for San Francisco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = ee.Geometry.Point([-122.4439, 37.7538])\n",
    "# point = ee.Geometry.Point([-87.7719, 41.8799])\n",
    "\n",
    "landsat = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR') \\\n",
    "    .filterBounds(point) \\\n",
    "    .filterDate('2020-01-01', '2020-12-31') \\\n",
    "    .sort('CLOUD_COVER') \\\n",
    "    .first() \\\n",
    "    .select('B[1-7]')\n",
    "\n",
    "vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 2000,\n",
    "    'bands': ['B4', 'B3', 'B2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cd89d2e09b4fbcb732bf888f1489ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.75379999999999, -122.44390000000001], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# landsat = landsat.updateMask(waterMask)\n",
    "# print(landsat.getInfo())\n",
    "Map.centerObject(point, 8)\n",
    "Map.addLayer(landsat, vis_params, 'Natural color composite')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define areas that have unique characteristics: bare soil, water, vegetation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use NDVI for help in diferentiating these areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi=landsat.normalizedDifference(['B5', 'B4'])\n",
    "vegPalette = ['blue','brown','yellow', 'green'] #'white','orange',,'teal','navy''lime',\n",
    "Map.addLayer(ndvi,{min:0, max: 1.0, 'palette': vegPalette},'ndvi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cd89d2e09b4fbcb732bf888f1489ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[37.75379999999999, -122.44390000000001], controls=(WidgetControl(options=['position', 'transparent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FOR BARE SOIL: \\\n",
    "# how I did this: \n",
    "# 1. I zoomed into the Landsat image to a bare soil area\n",
    "# 2. Click on the polygon icon of the left, and define an area with points, forming a closed polygon\n",
    "# 3. Run this cell. The last draw polygon is stored in \"Map.user_roi\"\n",
    "polygon = Map.user_roi\n",
    "\n",
    "# Or you can enter defined coordinates as the commented lines below.\n",
    "# // Create an ee.Geometry.\n",
    "# polygon = ee.Geometry.Polygon([\n",
    "#                   [-121.39030016076934, 37.60807367330306],\n",
    "#                   [-121.37889487541446, 37.61763764877222],\n",
    "#                   [-121.38989113432118, 37.62488608266359],\n",
    "#                   [-121.4012069200709, 37.615507786825766]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "baresoil = ee.Feature(polygon, {'class': 2, 'name': 'bare soil'});\n",
    "Map.addLayer(baresoil, {'fill_color':'yellow', 'outline': 1}, name='baresoil')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR WATER\n",
    "# same procesure as described for soil, in this case, I looked at water areas\n",
    "# \n",
    "polygon = Map.user_roi\n",
    "\n",
    "# // Create an ee.Geometry.\n",
    "# polygon = ee.Geometry.Polygon([\n",
    "#                   [-122.27695595509044, 37.6833127863229],\n",
    "#                   [-122.26635383955467, 37.683182346233664],\n",
    "#                   [-122.26478644790062, 37.70212710506073],\n",
    "#                   [-122.27107078047028, 37.70228065145053],\n",
    "#                   [-122.27474738958558, 37.701963093009745]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "water = ee.Feature(polygon, {'class': 0, 'name': 'water'});\n",
    "Map.addLayer(water, {'fill_color':'blue', 'outline': 1}, name='water')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR VEGETATION\n",
    "# same procedure for water and soil, in this case I looked into a forest area\n",
    "polygon = Map.user_roi\n",
    "\n",
    "# // Create an ee.Geometry.\n",
    "# polygon = ee.Geometry.Polygon([\n",
    "#                 [-122.24448548567862, 37.21542815360734],\n",
    "#                 [-122.240411435295, 37.21551898615349],\n",
    "#                 [-122.23457428064451, 37.21555749104616],\n",
    "#                 [-122.23385777982398, 37.23144541800057],\n",
    "#                 [-122.24444605659103, 37.23132764751063]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "vegetation = ee.Feature(polygon, {'class': 1, 'name': 'vegetation'});\n",
    "Map.addLayer(vegetation, {'fill_color':'green', 'outline': 1}, name='vegetation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Features into a Feature Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingFeatures = ee.FeatureCollection([water, vegetation, baresoil])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the bands of the Landsat composite to be used as predictors (i.e. the elements of p):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionBands = ['B2', 'B3', 'B4', 'B5' ,'B6','B7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the merged FeatureCollection, each Feature should have a property called 'class' where the classes are consecutive integers, one for each class, starting at 0. Verify that this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': None, 'id': '0', 'properties': {'class': 0, 'name': 'water'}}\n"
     ]
    }
   ],
   "source": [
    "print(trainingFeatures.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Create a training set T for the classifier by sampling the Landsat composite with the merged features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierTraining = landsat.select(predictionBands).sampleRegions(\n",
    "      collection= trainingFeatures, \n",
    "      properties= ['class'], \n",
    "      scale= 90\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Randomly split the data into 60% for training, and 40% for testing\n",
    "trainingTesting = classifierTraining.randomColumn('random',111009);\n",
    "\n",
    "training = trainingTesting.filter(ee.Filter.lt('random', 0.6));\n",
    "\n",
    "testing = trainingTesting.filter(ee.Filter.gte('random', 0.6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Non-linear regression functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a pletora of options for classification in Google Earth Engine. Here is an screenshot of these options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/vROsEiq.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ![](https://i.imgur.com/vROsEiq.png)\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://i.imgur.com/vROsEiq.png\")#, width=100, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For example, a Classification and Regression Tree (CART, see Brieman et al. 1984) is a machine learning algorithm that can learn non-linear patterns in your data.  Reusing the T table (without the constant term), train a CART as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartclassifier = ee.Classifier.smileCart(minLeafPopulation=1).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make predictions over the input imagery (classify in this context is a misnomer):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "EEException",
     "evalue": "No valid training data were found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps?fields=name&alt=json returned \"No valid training data were found.\". Details: \"No valid training data were found.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_474/1855898198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcartClasifficationImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlandsat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionBands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcartclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m Map.addLayer(cartClasifficationImage, {'min': 0, 'max': 2,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                    'palette':['blue', 'green','yellow']},'CART classification');\n\u001b[1;32m      5\u001b[0m \u001b[0mMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/geemap/geemap.py\u001b[0m in \u001b[0;36madd_ee_layer\u001b[0;34m(self, ee_object, vis_params, name, shown, opacity)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m         \u001b[0mmap_id_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMapId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m         tile_layer = ipyleaflet.TileLayer(\n\u001b[1;32m   1403\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_id_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tile_fetcher\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/ee/image.py\u001b[0m in \u001b[0;36mgetMapId\u001b[0;34m(self, vis_params)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mvis_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_visualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mrequest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvis_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMapId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/ee/data.py\u001b[0m in \u001b[0;36mgetMapId\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    573\u001b[0m   \u001b[0;31m# Make it return only the name field, as otherwise it echoes the entire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;31m# request, which might be large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m   result = _execute_cloud_call(\n\u001b[0m\u001b[1;32m    576\u001b[0m       _get_cloud_api_resource().projects().maps().create(\n\u001b[1;32m    577\u001b[0m           parent=_get_projects_path(), fields='name', body=request))\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/ee/data.py\u001b[0m in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mgoogleapiclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0m_translate_cloud_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEEException\u001b[0m: No valid training data were found."
     ]
    }
   ],
   "source": [
    "cartClasifficationImage = landsat.select(predictionBands).classify(cartclassifier);\n",
    "\n",
    "Map.addLayer(cartClasifficationImage, {'min': 0, 'max': 2,\n",
    "                                   'palette':['blue', 'green','yellow']},'CART classification');\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfClassification = ee.Classifier.smileRandomForest(numberOfTrees=13, seed=111009).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the RF regression on the landsat image\n",
    "rfClassificationImage = landsat.select(predictionBands).classify(rfClassification);\n",
    "    \n",
    "# // Visualize the RF regression\n",
    "Map.addLayer(rfClassificationImage,  {'min': 0, 'max': 2,\n",
    "                                   'palette':['blue','green', 'yellow']}, 'RF classification');\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee.Classifier.libsvm(decisionProcedure, svmType, kernelType, shrinking, degree, gamma, coef0, cost, nu, terminationEpsilon, lossEpsilon, oneClass)\n",
    "\n",
    "# // Create an SVM classifier with custom parameters.\n",
    "svClassification = ee.Classifier.libsvm(svmType='C_SVC',kernelType='RBF',gamma=0.01).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the RF regression on the landsat image\n",
    "svClassificationImage = landsat.select(predictionBands).classify(svClassification);\n",
    "    \n",
    "# // Visualize the RF regression\n",
    "Map.addLayer(svClassificationImage,{'min': 0, 'max': 2,\n",
    "                                   'palette':['blue', 'green','yellow']}, 'SV CLassification');\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classification context, accuracy measurements are often derived from a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.\tPrint the confusion matrix and expand the object to inspect the matrix.  The entries represent number of pixels.  Items on the diagonal represent correct classification.  Items off the diagonal are misclassifications, where the class in row i is classified as column j.  It's also possible to get basic descriptive statistics from the confusion matrix.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the CART classification on the test set\n",
    "\n",
    "test=testing.classify(cartclassifier)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the RF classification on the test set\n",
    "\n",
    "test=testing.classify(rfClassification)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');\n",
    "\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the SVR classification on the test set\n",
    "\n",
    "test=testing.classify(svClassification)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');\n",
    "\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Hyperparameters tuning\n",
    "\n",
    "A random forest is a collection of random trees the predictions of which are used to compute an average (regression) or vote on a label (classification).  Note that the only parameter to the classifier is the number of trees.  How many trees should you use?  Making that choice is best done by hyperparameter tuning.  For example, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrees = ee.List.sequence(1, 20, 1)\n",
    "\n",
    "\n",
    "def trees(t):\n",
    "    rfclass = ee.Classifier.smileRandomForest(numberOfTrees=t, seed=111009).train(\n",
    "    features= training, \n",
    "    classProperty= 'class', \n",
    "    inputProperties= predictionBands)\n",
    "    \n",
    "    rfTesting = testing.classify(rfclass)\n",
    "    testAccuracy = rfTesting.errorMatrix('class', 'classification');\n",
    "    kappa= testAccuracy.kappa();       \n",
    "    return kappa\n",
    "\n",
    "\n",
    "kappa_trees=numTrees.map(trees)\n",
    "value_info = kappa_trees.getInfo()\n",
    "\n",
    "# print(rmse_trees.getInfo())\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.DataFrame(value_info,columns=['kappa'])\n",
    "df['numTrees'] = numTrees.getInfo() \n",
    "\n",
    "ax =df.plot.line(x='numTrees', \n",
    "             y='kappa',\n",
    "             title= 'Impact of Number of Trees in Random Forest'\n",
    "             )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_vals = ee.List.sequence(0.01, 0.2, 0.05)\n",
    "\n",
    "\n",
    "def gammas(t):\n",
    "    svclass = ee.Classifier.libsvm(svmType='C_SVC',kernelType='RBF',gamma=t).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )\n",
    "    \n",
    "    svTesting = testing.classify(svclass)\n",
    "    testAccuracy = svTesting.errorMatrix('class', 'classification');\n",
    "    kappa= testAccuracy.kappa();       \n",
    "    return kappa\n",
    "\n",
    "\n",
    "kappa_gama=gamma_vals.map(gammas)\n",
    "value_info = kappa_gama.getInfo()\n",
    "\n",
    "# print(rmse_gama.getInfo())\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.DataFrame(value_info,columns=['kappa'])\n",
    "df['Gamma'] = gamma_vals.getInfo() \n",
    "\n",
    "ax =df.plot.line(x='Gamma', \n",
    "             y='kappa',\n",
    "             title= 'Impact of Gamma in SV'\n",
    "             )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now for Cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_vals = ee.List.sequence(1, 20, 1)\n",
    "\n",
    "\n",
    "def leaves(t):\n",
    "    cartclass= ee.Classifier.smileCart(minLeafPopulation=t).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )\n",
    "    \n",
    "    cartTesting = testing.classify(cartclass)\n",
    "    testAccuracy = cartTesting.errorMatrix('class', 'classification');\n",
    "    kappa= testAccuracy.kappa();       \n",
    "    return kappa\n",
    "\n",
    "\n",
    "kappa_leaf=leaf_vals.map(leaves)\n",
    "value_info = kappa_leaf.getInfo()\n",
    "\n",
    "# print(rmse_gama.getInfo())\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.DataFrame(value_info,columns=['kappa'])\n",
    "df['leaf'] = leaf_vals.getInfo() \n",
    "\n",
    "ax =df.plot.line(x='leaf', \n",
    "             y='kappa',\n",
    "             title= 'Impact of minLeafPopulation in cart'\n",
    "             )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "Recreate this notebook for Florida, a humid climate with a variety of forest (natural to agriculture). Make sure your SVC and Random Forest uses the tuned hyperparameters when discussing your accuracy found. Are the models behaving similarly? Do they statistically perform different than this example? Discuss it.\n",
    "\n",
    "Note: if after a while the code does not run, or shows an error, reduce the size of the polygons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
